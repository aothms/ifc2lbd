"""Streaming TTL writer for IFC files using ifcopenshell.stream2
 I would say. Use TTL_writer.py
"""

from collections import defaultdict
from typing import Any, Dict
from pathlib import Path
import ifcopenshell
import ifcopenshell.ifcopenshell_wrapper as wrapper
import datetime


def _build_entity_type_map(input_ifc_path: str) -> dict:
    """
    This is only when you want to have the instance names the same as in the full ifcOWL.
    First pass: Build mapping of entity ID -> entity type.
    This allows us to resolve references correctly in the second pass.
    
    Args:
        input_ifc_path: Path to IFC file
        
    Returns:
        Dictionary mapping entity IDs to their types {1: 'IfcOwnerHistory', 2: 'IfcPerson', ...}
    """
    entity_types = {}
    for entity_dict in ifcopenshell.stream2(input_ifc_path):
        entity_id = entity_dict.get('id')
        entity_type = entity_dict.get('type')
        if entity_id and entity_type:
            entity_types[entity_id] = entity_type
    return entity_types


def _format_turtle_value(val, inst_prefix, xsd_prefix, entity_types=None):
    """
    Format value for Turtle syntax.
    
    Args:
        val: Value to format
        inst_prefix: Instance namespace prefix (not used currently)
        xsd_prefix: XSD namespace prefix (not used currently)
        entity_types: Optional dict mapping entity IDs to types for proper reference formatting
    """
    val_type = type(val)
    
    if val_type is str:
        return f'"{val}"'
    elif val_type is int:
        return f'"{val}"^^xsd:integer'
    elif val_type is float:
        return f'"{val}"^^xsd:double'
    elif val_type is bool:
        return f'"{str(val).lower()}"^^xsd:boolean'
    elif isinstance(val, dict) and 'ref' in val:
        # Handle reference dictionaries from stream2
        ref_id = val['ref']
        if entity_types and ref_id in entity_types:
            # Writing inst:IfcPerson_3 instead of inst:Entity_3
            return f"inst:{entity_types[ref_id]}_{ref_id}"
        else:
            # Fallback if no type map provided
            return f"inst:ref_{ref_id}"
    else:
        return f'"{str(val)}"'


def string_writer_mini_ifcOWL_stream(input_ifc_path: str, output_ttl_path: str, namespaces: Dict[str, str]):
    """
    Stream an IFC file and write to Turtle TTL format (mini ifcOWL style).

    Counting of triples might be off (mainly due to collection).
    
    Uses two-pass approach:
    1. First pass: Build lightweight ID->type mapping
    2. Second pass: Stream and write with correct entity references
    """
    BASE = namespaces.get("BASE", "http://example.org/base#")
    INST = namespaces["inst"]
    XSD = namespaces["xsd"]

    # FIRST PASS: Build instance type mapping
    entity_types = _build_entity_type_map(input_ifc_path)

    triple_count = 0

    # SECOND PASS: Write TTL with correct references
    with open(output_ttl_path, 'w', encoding='utf-8') as f:
        f.write(f"# Turtle TTL output generated by LBD writer (streaming mode).\n")
        f.write(f"# baseURI: {BASE}\n")
        f.write(f"# imports: {namespaces['mifc']}\n")
        f.write("\n")
        f.write(f"BASE <{BASE}>\n")
        for prefix, uri in namespaces.items():
            if prefix != "BASE":
                f.write(f"PREFIX {prefix}: <{uri}>\n")
        f.write("\n")
        f.write(f"inst:\ta\towl:Ontology ;\n")
        f.write(f"\towl:imports\tifc: .\n\n")

        triple_count += 2

        for entity_dict in ifcopenshell.stream2(input_ifc_path):
            entity_type = entity_dict.get('type')
            entity_id = entity_dict.get('id')
            
            if not entity_type or not entity_id:
                continue
            
            subj = f"inst:{entity_type}_{entity_id}"
            pred_obj = defaultdict(list)
            collection_metadata = {}  # Track collection sizes for counting
            
            for attr_name, attr_value in entity_dict.items():
                if attr_name in ('type', 'id') or attr_value is None:
                    continue
                
                pred = f"mifc:{attr_name}"
                
                if isinstance(attr_value, (list, tuple)):
                    if not attr_value:
                        # Empty list/tuple â†’ empty RDF collection: () = rdf:nil
                        pred_obj[pred].append("()")
                        collection_metadata[pred] = ('empty', 0)
                    elif isinstance(attr_value[0], (list, tuple)):
                        # NESTED LISTS: ( ( 1 2 3 ) ( 4 5 6 ) ... )
                        # Used for: Normals, CoordIndex, CoordList - preserves order at both levels
                        inner_collections = []
                        inner_sizes = []
                        for nested_item in attr_value:
                            if nested_item is None:
                                continue
                            items = [_format_turtle_value(item, INST, XSD, entity_types) 
                                    for item in nested_item if item is not None]
                            if items:
                                inner_collections.append(f"( {' '.join(items)} )")
                                inner_sizes.append(len(items))
                        if inner_collections:
                            pred_obj[pred].append(f"( {' '.join(inner_collections)} )")
                            collection_metadata[pred] = ('nested', len(inner_collections), inner_sizes)
                    elif isinstance(attr_value[0], dict) and 'ref' in attr_value[0]:
                        # LIST OF REFERENCES: ref_1 , ref_2 , ref_3
                        # Used for: RelatedObjects, HasAssociations, etc. - unordered sets
                        for item in attr_value:
                            if item is None:
                                continue
                            obj = _format_turtle_value(item, INST, XSD, entity_types)
                            pred_obj[pred].append(obj)
                    else:
                        # FLAT LIST OF PRIMITIVES: ( 1.0 2.0 3.0 )
                        # Used for: Coordinates, DirectionRatios - preserves order
                        items = [_format_turtle_value(item, INST, XSD, entity_types) 
                                for item in attr_value if item is not None]
                        if items:
                            pred_obj[pred].append(f"( {' '.join(items)} )")
                            collection_metadata[pred] = ('flat', len(items))
                else:
                    obj = _format_turtle_value(attr_value, INST, XSD, entity_types)
                    pred_obj[pred].append(obj)
            
            f.write(f"{subj} a mifc:{entity_type}")
            triple_count += 1  # Count the rdf:type triple
            
            if pred_obj:
                f.write(" ;\n")
                predicates = list(pred_obj.items())
                for i, (pred, objs) in enumerate(predicates):
                    objects_str = " , ".join(objs)
                    
                    # Count triples correctly based on collection type
                    if pred in collection_metadata:
                        coll_type = collection_metadata[pred][0]
                        if coll_type == 'empty':
                            # Empty collection: 1 triple (subject predicate rdf:nil)
                            triple_count += 1
                        elif coll_type == 'flat':
                            # Flat collection ( item1 item2 ... itemN )
                            # Expands to: 1 + 2*N triples
                            n = collection_metadata[pred][1]
                            triple_count += 1 + (2 * n)
                        elif coll_type == 'nested':
                            # Nested collection ( ( i1 i2 ) ( i3 i4 ) ... )
                            # Outer: 1 + 2*M (M = number of inner collections)
                            # Each inner: 2*N_i (NOT 1+2*N_i, inner blanks are already objects in outer)
                            m = collection_metadata[pred][1]
                            inner_sizes = collection_metadata[pred][2]
                            triple_count += 1 + (2 * m)  # Outer collection
                            for n_i in inner_sizes:
                                triple_count += 2 * n_i  # Each inner collection (no +1)
                    else:
                        # Non-collection objects (simple values or refs)
                        triple_count += len(objs)
                    
                    if i < len(predicates) - 1:
                        f.write(f"\t{pred} {objects_str} ;\n")
                    else:
                        f.write(f"\t{pred} {objects_str} .\n\n")
            else:
                f.write(" .\n\n")

    return {
        'entities_processed': len(entity_types),
        'triples_written': triple_count
    }

# This one is still not functioning. So just a placeholder.

def string_writer_ifcOWL_stream(input_ifc_path: str, output_ttl_path: str, namespaces: Dict[str, str]):
    """
    Stream an IFC file and write to Turtle TTL format following full ifcOWL. Just a place holder for now.
    
    Uses two-pass approach:
    1. First pass: Build lightweight ID->type mapping
    2. Second pass: Stream and write with correct entity references
    """

    pass